{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import os\n",
    "\n",
    "import boto3\n",
    "import re # python regex module\n",
    "from sagemaker import get_execution_role\n",
    "import sagemaker\n",
    "\n",
    "# SDK 2 serializers and deserializers\n",
    "from sagemaker.serializers import CSVSerializer\n",
    "from sagemaker.deserializers import JSONDeserializer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>XGBoost Cloud Prediction - Iris Classification</h1>\n",
    "<h4>Invoke SageMaker Prediction Service</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Acquire a realtime endpoint\n",
    "endpoint_name = 'xgboost-iris-v1' #DWB# Checked from console - matches\n",
    "predictor = sagemaker.predictor.Predictor (endpoint_name=endpoint_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.serializer = CSVSerializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test predictive quality against data in validation file\n",
    "df_all = pd.read_csv('iris_validation.csv',\n",
    "                     names=['encoded_class','sepal_length','sepal_width','petal_length','petal_width'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to pass an array to the prediction\n",
    "# can pass a numpy array or a list of values [[19,1],[20,1]]\n",
    "# arr_test = df_all.as_matrix(['sepal_length', 'sepal_width', 'petal_length','petal_width'])\n",
    "arr_test = df_all[['sepal_length', 'sepal_width', 'petal_length','petal_width']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(arr_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_test[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = predictor.predict(arr_test[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DWB#  I think that repeat might not be on purpose;\n",
    "#DWB#+ Let's check instead result.shape\n",
    "try:\n",
    "    print(str(result.shape))\n",
    "except Exception as e:\n",
    "    print('', file=sys.stderr)\n",
    "    print(\"That didn't work.\", file=sys.stderr)\n",
    "    print(f\"str(e) is: `{str(e)}`\", file=sys.stderr)\n",
    "    print('', file=sys.stderr)\n",
    "finally:\n",
    "    print(\"That tells us what we need to know.\")\n",
    "##endof:  try/except/finally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For large number of predictions, we can split the input data and\n",
    "# Query the prediction service.\n",
    "# array_split is convenient to specify how many splits are needed\n",
    "\n",
    "# Splitting using regular expression as xgboost 1-2-2 is returning\n",
    "# predicted values with inconsistent delimiters (comma, newline or both)\n",
    "\n",
    "# pattern looks for one or more of non-numeric characters\n",
    "pattern = r'[^0-9.]+'\n",
    "\n",
    "predictions = []\n",
    "#DWB# added the next 2 lines\n",
    "total_row_count = 0\n",
    "n_columns_and_count = {}\n",
    "\n",
    "for arr in np.array_split(arr_test,10):\n",
    "    result = predictor.predict(arr)    \n",
    "    result = re.split(pattern,result.decode(\"utf-8\"))\n",
    "    print (arr.shape)\n",
    "    #DWB# Here is what we can match up\n",
    "    #DWB# <shape-consistency-check>\n",
    "    this_chunk_shape = arr.shape\n",
    "    this_row_count = this_chunk_shape[0]\n",
    "    total_row_count += this_row_count\n",
    "    this_col_count = this_chunk_shape[1]\n",
    "    if this_col_count in n_columns_and_count:\n",
    "        n_columns_and_count[this_col_count] += 1\n",
    "    else:\n",
    "        n_columns_and_count[this_col_count] = 1\n",
    "    ##endof:  if/else this_col_count in n_columns_and_count\n",
    "    #DWB# </shape-consistency-check>\n",
    "    predictions += [int(float(r)) for r in result if r != \"\"]\n",
    "\n",
    "#DWB# It's me from here on out.\n",
    "\n",
    "print()\n",
    "print(\"# Looking at the chunks all together #\")\n",
    "print(f\"The total number of rows is: {total_row_count}\")\n",
    "print(\"For each row, I counted the number of columns;\")\n",
    "print(\"here is the distribution of column counts.\")\n",
    "print(n_columns_and_count)\n",
    "print()\n",
    "print(\"Having inspected that, I can see that\")\n",
    "print(\"the shape of all the chunks combined is\")\n",
    "print(\"(45, 4), which matches our original\")\n",
    "print(\"arr_test.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(['Iris-setosa', 'Iris-versicolor', 'Iris-virginica'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['class'] = le.inverse_transform(df_all.encoded_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['predicted_class']=le.inverse_transform(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Confusion matrix - Actual versus Predicted')\n",
    "pd.crosstab(df_all['class'], df_all['predicted_class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics as metrics\n",
    "print(metrics.classification_report(df_all['class'], df_all['predicted_class']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DWB#  Still in this second one there's no Endpoint-deletion Code.\n",
    "#DWB#+ I will put some in, here.\n",
    "#DWB#+ As Chandra wrote with the previous such code\n",
    "# Delete Endpoint to prevent unnecessary charges\n",
    "predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  I checked the list of endpoints from the AWS Console > Sagemaker ...\n",
    "#+ and the endpoint that was there is gone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
